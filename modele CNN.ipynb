{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a708a9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar100\n",
    "from tensorflow.keras import layers, models, datasets\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Activation, Dropout\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "901a96d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nombre d'image de train 50000\n",
      "nombre d'image de test 10000\n",
      "nombre de classe 100\n",
      "Profondeur (depth) : 32\n",
      "Hauteur (height)   : 32\n",
      "Largeur (width)    : 3\n"
     ]
    }
   ],
   "source": [
    "    (train_images, train_labels), (test_images, test_labels) = datasets.cifar100.load_data()\n",
    "\n",
    "\n",
    "    num_train,depth,height,width=train_images.shape\n",
    "    print(\"nombre d'image de train\", num_train)\n",
    "    num_test=test_images.shape[0]\n",
    "    print(\"nombre d'image de test\", num_test)\n",
    "    num_classes=np.unique(train_labels).shape[0]\n",
    "    print(\"nombre de classe\", num_classes)\n",
    "    input_images=(depth,height,width)\n",
    "    print(\"Profondeur (depth) :\", depth)\n",
    "    print(\"Hauteur (height)   :\", height)\n",
    "    print(\"Largeur (width)    :\", width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ad7de94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encodage Ã  chaud\n",
    "train_labels = to_categorical(train_labels, 100)\n",
    "test_labels = to_categorical(test_labels, 100)\n",
    "\n",
    "# Normaliser les pixeles entre l'intervalle 0 et 1\n",
    "train_images = train_images.astype('float32')\n",
    "test_images = test_images.astype('float32')\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01994e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_35 (Conv2D)          (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " activation_55 (Activation)  (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_20 (MaxPooli  (None, 16, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_36 (Conv2D)          (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " activation_56 (Activation)  (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_37 (Conv2D)          (None, 16, 16, 64)        36928     \n",
      "                                                                 \n",
      " activation_57 (Activation)  (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_21 (MaxPooli  (None, 8, 8, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 8, 8, 64)          0         \n",
      "                                                                 \n",
      " conv2d_38 (Conv2D)          (None, 8, 8, 128)         73856     \n",
      "                                                                 \n",
      " activation_58 (Activation)  (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " conv2d_39 (Conv2D)          (None, 8, 8, 128)         147584    \n",
      "                                                                 \n",
      " activation_59 (Activation)  (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " max_pooling2d_22 (MaxPooli  (None, 4, 4, 128)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 4, 4, 128)         0         \n",
      "                                                                 \n",
      " conv2d_40 (Conv2D)          (None, 4, 4, 256)         295168    \n",
      "                                                                 \n",
      " activation_60 (Activation)  (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " conv2d_41 (Conv2D)          (None, 4, 4, 256)         590080    \n",
      "                                                                 \n",
      " activation_61 (Activation)  (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " max_pooling2d_23 (MaxPooli  (None, 2, 2, 256)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 2, 2, 256)         0         \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 256)               262400    \n",
      "                                                                 \n",
      " activation_62 (Activation)  (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 512)               131584    \n",
      "                                                                 \n",
      " activation_63 (Activation)  (None, 512)               0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 1024)              525312    \n",
      "                                                                 \n",
      " activation_64 (Activation)  (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 100)               102500    \n",
      "                                                                 \n",
      " activation_65 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2184804 (8.33 MB)\n",
      "Trainable params: 2184804 (8.33 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "782/782 [==============================] - 65s 81ms/step - loss: 4.6054 - accuracy: 0.0107\n",
      "Epoch 2/100\n",
      "782/782 [==============================] - 68s 87ms/step - loss: 4.6053 - accuracy: 0.0103\n",
      "Epoch 3/100\n",
      "782/782 [==============================] - 69s 88ms/step - loss: 4.6051 - accuracy: 0.0111\n",
      "Epoch 4/100\n",
      "782/782 [==============================] - 70s 89ms/step - loss: 4.6052 - accuracy: 0.0091\n",
      "Epoch 5/100\n",
      "782/782 [==============================] - 69s 88ms/step - loss: 4.6053 - accuracy: 0.0105\n",
      "Epoch 6/100\n",
      "782/782 [==============================] - 69s 89ms/step - loss: 4.6051 - accuracy: 0.0105\n",
      "Epoch 7/100\n",
      "782/782 [==============================] - 69s 88ms/step - loss: 4.6050 - accuracy: 0.0101\n",
      "Epoch 8/100\n",
      "782/782 [==============================] - 71s 90ms/step - loss: 4.6050 - accuracy: 0.0106\n",
      "Epoch 9/100\n",
      "782/782 [==============================] - 68s 87ms/step - loss: 4.6050 - accuracy: 0.0100\n",
      "Epoch 10/100\n",
      "782/782 [==============================] - 68s 88ms/step - loss: 4.6049 - accuracy: 0.0104\n",
      "Epoch 11/100\n",
      "782/782 [==============================] - 69s 89ms/step - loss: 4.6049 - accuracy: 0.0100\n",
      "Epoch 12/100\n",
      "782/782 [==============================] - 69s 88ms/step - loss: 4.6047 - accuracy: 0.0101\n",
      "Epoch 13/100\n",
      "782/782 [==============================] - 69s 89ms/step - loss: 4.6047 - accuracy: 0.0109\n",
      "Epoch 14/100\n",
      "782/782 [==============================] - 69s 88ms/step - loss: 4.6044 - accuracy: 0.0109\n",
      "Epoch 15/100\n",
      "782/782 [==============================] - 69s 88ms/step - loss: 4.6039 - accuracy: 0.0106\n",
      "Epoch 16/100\n",
      "782/782 [==============================] - 73s 93ms/step - loss: 4.6032 - accuracy: 0.0107\n",
      "Epoch 17/100\n",
      "782/782 [==============================] - 68s 87ms/step - loss: 4.6009 - accuracy: 0.0107\n",
      "Epoch 18/100\n",
      "782/782 [==============================] - 68s 87ms/step - loss: 4.5923 - accuracy: 0.0115\n",
      "Epoch 19/100\n",
      "782/782 [==============================] - 68s 87ms/step - loss: 4.5692 - accuracy: 0.0123\n",
      "Epoch 20/100\n",
      "782/782 [==============================] - 68s 87ms/step - loss: 4.5470 - accuracy: 0.0132\n",
      "Epoch 21/100\n",
      "782/782 [==============================] - 68s 87ms/step - loss: 4.5296 - accuracy: 0.0154\n",
      "Epoch 22/100\n",
      "782/782 [==============================] - 68s 87ms/step - loss: 4.5190 - accuracy: 0.0171\n",
      "Epoch 23/100\n",
      "782/782 [==============================] - 68s 87ms/step - loss: 4.5127 - accuracy: 0.0188\n",
      "Epoch 24/100\n",
      "782/782 [==============================] - 68s 87ms/step - loss: 4.5049 - accuracy: 0.0185\n",
      "Epoch 25/100\n",
      "782/782 [==============================] - 68s 87ms/step - loss: 4.4991 - accuracy: 0.0190\n",
      "Epoch 26/100\n",
      "782/782 [==============================] - 68s 87ms/step - loss: 4.4922 - accuracy: 0.0202\n",
      "Epoch 27/100\n",
      "782/782 [==============================] - 69s 88ms/step - loss: 4.4856 - accuracy: 0.0209\n",
      "Epoch 28/100\n",
      "782/782 [==============================] - 68s 86ms/step - loss: 4.4798 - accuracy: 0.0208\n",
      "Epoch 29/100\n",
      "782/782 [==============================] - 69s 88ms/step - loss: 4.4710 - accuracy: 0.0232\n",
      "Epoch 30/100\n",
      "782/782 [==============================] - 70s 90ms/step - loss: 4.4606 - accuracy: 0.0238\n",
      "Epoch 31/100\n",
      "782/782 [==============================] - 69s 88ms/step - loss: 4.4500 - accuracy: 0.0249\n",
      "Epoch 32/100\n",
      "782/782 [==============================] - 68s 86ms/step - loss: 4.4392 - accuracy: 0.0258\n",
      "Epoch 33/100\n",
      "782/782 [==============================] - 66s 85ms/step - loss: 4.4278 - accuracy: 0.0260\n",
      "Epoch 34/100\n",
      "782/782 [==============================] - 67s 85ms/step - loss: 4.4158 - accuracy: 0.0283\n",
      "Epoch 35/100\n",
      "782/782 [==============================] - 67s 85ms/step - loss: 4.4058 - accuracy: 0.0278\n",
      "Epoch 36/100\n",
      "782/782 [==============================] - 66s 85ms/step - loss: 4.3938 - accuracy: 0.0282\n",
      "Epoch 37/100\n",
      "782/782 [==============================] - 67s 85ms/step - loss: 4.3806 - accuracy: 0.0296\n",
      "Epoch 38/100\n",
      "782/782 [==============================] - 66s 85ms/step - loss: 4.3642 - accuracy: 0.0277\n",
      "Epoch 39/100\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 4.3396 - accuracy: 0.0308\n",
      "Epoch 40/100\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 4.3152 - accuracy: 0.0317\n",
      "Epoch 41/100\n",
      "782/782 [==============================] - 66s 84ms/step - loss: 4.2964 - accuracy: 0.0324\n",
      "Epoch 42/100\n",
      "782/782 [==============================] - 65s 84ms/step - loss: 4.2807 - accuracy: 0.0344\n",
      "Epoch 43/100\n",
      "782/782 [==============================] - 66s 85ms/step - loss: 4.2672 - accuracy: 0.0363\n",
      "Epoch 44/100\n",
      "782/782 [==============================] - 67s 85ms/step - loss: 4.2525 - accuracy: 0.0363\n",
      "Epoch 45/100\n",
      "782/782 [==============================] - 67s 85ms/step - loss: 4.2454 - accuracy: 0.0368\n",
      "Epoch 46/100\n",
      "782/782 [==============================] - 66s 85ms/step - loss: 4.2344 - accuracy: 0.0383\n",
      "Epoch 47/100\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 4.2236 - accuracy: 0.0384\n",
      "Epoch 48/100\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 4.2144 - accuracy: 0.0398\n",
      "Epoch 49/100\n",
      "782/782 [==============================] - 67s 85ms/step - loss: 4.2039 - accuracy: 0.0410\n",
      "Epoch 50/100\n",
      "782/782 [==============================] - 67s 85ms/step - loss: 4.1965 - accuracy: 0.0398\n",
      "Epoch 51/100\n",
      "782/782 [==============================] - 67s 85ms/step - loss: 4.1873 - accuracy: 0.0422\n",
      "Epoch 52/100\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 4.1761 - accuracy: 0.0424\n",
      "Epoch 53/100\n",
      "782/782 [==============================] - 66s 84ms/step - loss: 4.1665 - accuracy: 0.0433\n",
      "Epoch 54/100\n",
      "782/782 [==============================] - 66s 84ms/step - loss: 4.1612 - accuracy: 0.0445\n",
      "Epoch 55/100\n",
      "782/782 [==============================] - 66s 84ms/step - loss: 4.1537 - accuracy: 0.0444\n",
      "Epoch 56/100\n",
      "782/782 [==============================] - 66s 84ms/step - loss: 4.1439 - accuracy: 0.0464\n",
      "Epoch 57/100\n",
      "782/782 [==============================] - 66s 85ms/step - loss: 4.1353 - accuracy: 0.0465\n",
      "Epoch 58/100\n",
      "782/782 [==============================] - 66s 84ms/step - loss: 4.1282 - accuracy: 0.0491\n",
      "Epoch 59/100\n",
      "782/782 [==============================] - 66s 84ms/step - loss: 4.1202 - accuracy: 0.0499\n",
      "Epoch 60/100\n",
      "782/782 [==============================] - 66s 84ms/step - loss: 4.1116 - accuracy: 0.0493\n",
      "Epoch 61/100\n",
      "782/782 [==============================] - 66s 84ms/step - loss: 4.1043 - accuracy: 0.0523\n",
      "Epoch 62/100\n",
      "782/782 [==============================] - 66s 84ms/step - loss: 4.0913 - accuracy: 0.0543\n",
      "Epoch 63/100\n",
      "782/782 [==============================] - 66s 85ms/step - loss: 4.0877 - accuracy: 0.0551\n",
      "Epoch 64/100\n",
      "782/782 [==============================] - 66s 84ms/step - loss: 4.0819 - accuracy: 0.0540\n",
      "Epoch 65/100\n",
      "782/782 [==============================] - 66s 84ms/step - loss: 4.0719 - accuracy: 0.0563\n",
      "Epoch 66/100\n",
      "782/782 [==============================] - 66s 84ms/step - loss: 4.0630 - accuracy: 0.0567\n",
      "Epoch 67/100\n",
      "782/782 [==============================] - 66s 84ms/step - loss: 4.0561 - accuracy: 0.0590\n",
      "Epoch 68/100\n",
      "782/782 [==============================] - 66s 85ms/step - loss: 4.0444 - accuracy: 0.0607\n",
      "Epoch 69/100\n",
      "782/782 [==============================] - 66s 84ms/step - loss: 4.0400 - accuracy: 0.0598\n",
      "Epoch 70/100\n",
      "782/782 [==============================] - 67s 85ms/step - loss: 4.0282 - accuracy: 0.0636\n",
      "Epoch 71/100\n",
      "782/782 [==============================] - 66s 84ms/step - loss: 4.0198 - accuracy: 0.0622\n",
      "Epoch 72/100\n",
      "782/782 [==============================] - 66s 85ms/step - loss: 4.0100 - accuracy: 0.0666\n",
      "Epoch 73/100\n",
      "782/782 [==============================] - 66s 84ms/step - loss: 3.9995 - accuracy: 0.0656\n",
      "Epoch 74/100\n",
      "782/782 [==============================] - 66s 84ms/step - loss: 3.9969 - accuracy: 0.0664\n",
      "Epoch 75/100\n",
      "782/782 [==============================] - 66s 84ms/step - loss: 3.9817 - accuracy: 0.0670\n",
      "Epoch 76/100\n",
      "782/782 [==============================] - 66s 84ms/step - loss: 3.9720 - accuracy: 0.0707\n",
      "Epoch 77/100\n",
      "782/782 [==============================] - 66s 85ms/step - loss: 3.9625 - accuracy: 0.0695\n",
      "Epoch 78/100\n",
      "782/782 [==============================] - 67s 85ms/step - loss: 3.9484 - accuracy: 0.0729\n",
      "Epoch 79/100\n",
      "782/782 [==============================] - 67s 85ms/step - loss: 3.9453 - accuracy: 0.0727\n",
      "Epoch 80/100\n",
      "782/782 [==============================] - 66s 84ms/step - loss: 3.9328 - accuracy: 0.0759\n",
      "Epoch 81/100\n",
      "782/782 [==============================] - 67s 85ms/step - loss: 3.9215 - accuracy: 0.0771\n",
      "Epoch 82/100\n",
      "782/782 [==============================] - 68s 86ms/step - loss: 3.9114 - accuracy: 0.0761\n",
      "Epoch 83/100\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 3.9014 - accuracy: 0.0783\n",
      "Epoch 84/100\n",
      "782/782 [==============================] - 68s 87ms/step - loss: 3.8968 - accuracy: 0.0789\n",
      "Epoch 85/100\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 3.8825 - accuracy: 0.0822\n",
      "Epoch 86/100\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 3.8713 - accuracy: 0.0815\n",
      "Epoch 87/100\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 3.8621 - accuracy: 0.0850\n",
      "Epoch 88/100\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 3.8495 - accuracy: 0.0844\n",
      "Epoch 89/100\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 3.8419 - accuracy: 0.0849\n",
      "Epoch 90/100\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 3.8365 - accuracy: 0.0867\n",
      "Epoch 91/100\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 3.8300 - accuracy: 0.0878\n",
      "Epoch 92/100\n",
      "782/782 [==============================] - 68s 87ms/step - loss: 3.8182 - accuracy: 0.0895\n",
      "Epoch 93/100\n",
      "782/782 [==============================] - 68s 87ms/step - loss: 3.8073 - accuracy: 0.0906\n",
      "Epoch 94/100\n",
      "782/782 [==============================] - 72s 92ms/step - loss: 3.7967 - accuracy: 0.0912\n",
      "Epoch 95/100\n",
      "782/782 [==============================] - 72s 92ms/step - loss: 3.7924 - accuracy: 0.0931\n",
      "Epoch 96/100\n",
      "782/782 [==============================] - 72s 92ms/step - loss: 3.7826 - accuracy: 0.0939\n",
      "Epoch 97/100\n",
      "782/782 [==============================] - 72s 92ms/step - loss: 3.7713 - accuracy: 0.0949\n",
      "Epoch 98/100\n",
      "782/782 [==============================] - 72s 92ms/step - loss: 3.7669 - accuracy: 0.0964\n",
      "Epoch 99/100\n",
      "782/782 [==============================] - 72s 93ms/step - loss: 3.7608 - accuracy: 0.0982\n",
      "Epoch 100/100\n",
      "782/782 [==============================] - 72s 93ms/step - loss: 3.7547 - accuracy: 0.0985\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1ca28ab6e90>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    filtre=3\n",
    "    #strides=1\n",
    "    convolution1=32\n",
    "    convolution2=64\n",
    "    convolution3=128\n",
    "    convolution4=256\n",
    "    pool_size=2\n",
    "    dropout1=0.25\n",
    "    dropout2=0.50\n",
    "    couche_cache1=256\n",
    "    couche_cache2=512\n",
    "    couche_cache3=1024\n",
    "    nombre_classes=100\n",
    "   \n",
    " \n",
    "    C1= Conv2D(convolution1,(filtre,filtre), padding='same', input_shape=input_images)\n",
    "    MP1= MaxPooling2D((pool_size, pool_size))\n",
    "\n",
    "    C2= Conv2D(convolution2,(filtre,filtre), padding='same')\n",
    "    C3= Conv2D(convolution2,(filtre,filtre), padding='same')\n",
    "    MP2= MaxPooling2D((pool_size, pool_size))\n",
    "    DO1= Dropout(dropout1)\n",
    "    \n",
    "    C4= Conv2D(convolution3,(filtre,filtre), padding='same')\n",
    "    C5= Conv2D(convolution3,(filtre,filtre), padding='same')\n",
    "    MP3= MaxPooling2D((pool_size, pool_size))\n",
    "    DO2= Dropout(dropout1)\n",
    "\n",
    "\n",
    "    C6= Conv2D(convolution4,(filtre,filtre), padding='same')\n",
    "    C7= Conv2D(convolution4,(filtre,filtre), padding='same')\n",
    "    MP4= MaxPooling2D((pool_size, pool_size))\n",
    "    DO3= Dropout(dropout1)\n",
    "\n",
    "    F1= Flatten()\n",
    "    D1= Dense(couche_cache1)\n",
    "    D2= Dense(couche_cache2)\n",
    "    D3= Dense(couche_cache3)\n",
    "    DO4= Dropout(dropout2)\n",
    "    \n",
    "    CL = Dense(nombre_classes)\n",
    "\n",
    "\n",
    "# CrÃ©ation du modÃ¨le CNN\n",
    "    model = models.Sequential()\n",
    "\n",
    "    model.add(C1)\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MP1)\n",
    "\n",
    "\n",
    "    model.add(C2)\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(C3)\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MP2)\n",
    "    model.add(DO1)\n",
    "\n",
    "    model.add(C4)\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(C5)\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MP3)\n",
    "    model.add(DO2)\n",
    "\n",
    "    model.add(C6)\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(C7)\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MP4)\n",
    "    model.add(DO3)\n",
    "\n",
    "    model.add(F1)\n",
    "\n",
    "    model.add(D1)\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(DO4)\n",
    "    model.add(D2)\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(DO4)\n",
    "    model.add(D3)\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(DO4)\n",
    "\n",
    "    model.add(CL)\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "# Compile the model\n",
    "    adadaleta=tf.keras.optimizers.legacy.Adadelta(\n",
    "    learning_rate=0.01,\n",
    "    rho=0.95,\n",
    "    decay=1e-07,\n",
    "    name='Adadelta')\n",
    "\n",
    "    model.compile(loss=categorical_crossentropy, optimizer=adadaleta, metrics=['accuracy'])\n",
    "   \n",
    "    # EntraÃ®ner le modÃ¨le\n",
    "    model.fit(train_images, train_labels, epochs=100, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e9b01bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 5s 13ms/step - loss: 3.7152 - accuracy: 0.1100\n",
      "Accuracy: 11.00%\n"
     ]
    }
   ],
   "source": [
    "# Ãvaluer le modÃ¨le\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(\"Accuracy: {:.2f}%\".format(test_acc * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3decb700",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
